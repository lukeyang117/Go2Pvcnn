# Go2 PVCNN-PPO è®­ç»ƒç³»ç»Ÿæ€»ç»“

## ğŸ“‹ ç³»ç»Ÿæ¦‚è¿°

æˆåŠŸå®ç°äº†åŸºäºPVCNNè¯­ä¹‰åˆ†å‰²çš„Go2å››è¶³æœºå™¨äººå¯¼èˆªè®­ç»ƒç³»ç»Ÿï¼Œä½¿ç”¨PPOç®—æ³•è®­ç»ƒå¸¦æœ‰è§†è§‰æ„ŸçŸ¥çš„ç­–ç•¥ç½‘ç»œã€‚

---

## ğŸ”§ æ ¸å¿ƒä¿®æ”¹æ¸…å•

### 1. PVCNNæ¨¡å‹é€‚é…ï¼ˆ3é€šé“è¾“å…¥ + 4ç±»åˆ«è¾“å‡ºï¼‰

**æ–‡ä»¶**: `Go2Pvcnn/go2_pvcnn/pvcnn_wrapper.py`

#### è¾“å…¥é€šé“é€‚é…ï¼ˆ9â†’3ï¼‰
- **åŸå§‹**: S3DISè®­ç»ƒæ—¶ä½¿ç”¨9é€šé“ï¼ˆXYZ + RGB + Normalsï¼‰
- **ä¿®æ”¹å**: Go2åªç”¨3é€šé“ï¼ˆXYZåæ ‡ï¼‰
- **å®ç°**:
  ```python
  # ç¬¬ä¸€å±‚å·ç§¯æƒé‡è£å‰ª
  if 'point_features.0' in key and 'weight' in key:
      if original_weight.shape[1] == 9:
          new_weight = original_weight[:, :3, ...]  # åªä¿ç•™XYZé€šé“
  ```

#### è¾“å‡ºç±»åˆ«é€‚é…ï¼ˆ13â†’4ï¼‰
- **åŸå§‹**: S3DISæœ‰13ä¸ªå®¤å†…åœºæ™¯ç±»åˆ«
- **ä¿®æ”¹å**: Go2ç¯å¢ƒ4ä¸ªç±»åˆ«
  - **Class 0**: Terrainï¼ˆåœ°å½¢ï¼Œå¯é€šè¡Œï¼‰
  - **Class 1**: CrackerBoxï¼ˆObject_0ï¼Œéšœç¢ç‰©ï¼‰
  - **Class 2**: SugarBoxï¼ˆObject_1ï¼Œéšœç¢ç‰©ï¼‰
  - **Class 3**: TomatoSoupCanï¼ˆObject_2ï¼Œéšœç¢ç‰©ï¼‰
- **å®ç°**:
  ```python
  # åˆ†ç±»å™¨è¾“å‡ºå±‚æƒé‡è£å‰ª
  if 'classifier' in key and original_param.shape[0] == 13:
      new_param = original_param[:4, ...]  # åªä¿ç•™å‰4ä¸ªç±»åˆ«
  ```

---

### 2. ç‚¹äº‘é¢„å¤„ç†ä¼˜åŒ–

**æ–‡ä»¶**: `Go2Pvcnn/go2_pvcnn/mdp/observations.py`

#### æ— æ•ˆç‚¹è¿‡æ»¤
```python
# è¿‡æ»¤Inf/NaN/é›¶ç‚¹
valid_mask = ~(torch.isinf(point_cloud).any(dim=-1) | 
               torch.isnan(point_cloud).any(dim=-1) |
               (point_cloud.abs().sum(dim=-1) < 1e-6))
valid_points = point_cloud[valid_mask]
```

#### æ™ºèƒ½é‡‡æ ·åˆ°2046ç‚¹
- **ç‚¹å¤ªå¤š**: ä½¿ç”¨FPSï¼ˆæœ€è¿œç‚¹é‡‡æ ·ï¼‰
  ```python
  from pytorch3d.ops import sample_farthest_points
  sampled_points, _ = sample_farthest_points(valid_points, K=2046)
  ```
- **ç‚¹å¤ªå°‘**: å¤åˆ¶ç‚¹åˆ°ç›®æ ‡æ•°é‡
  ```python
  num_repeats = (2046 + num_valid - 1) // num_valid
  point_cloud = valid_points.repeat(num_repeats, 1)[:2046]
  ```

---

### 3. Cost Mapç”Ÿæˆ

**æ–‡ä»¶**: `Go2Pvcnn/go2_pvcnn/mdp/cost_map.py`

#### 3é€šé“ä»£ä»·åœ°å›¾ï¼ˆ64Ã—64ç½‘æ ¼ï¼‰
```python
class CostMapGenerator:
    def generate_cost_map(point_xyz, semantic_logits, semantic_confidence):
        # Channel 0: è·ç¦»ä»£ä»·ï¼ˆåˆ°æœ€è¿‘éšœç¢ç‰©ï¼‰
        distance_cost = compute_distance_cost(obstacle_map)
        
        # Channel 1: é«˜åº¦æ¢¯åº¦ä»£ä»·ï¼ˆåœ°å½¢é™¡å³­åº¦ï¼‰
        gradient_cost = compute_gradient_cost(height_map)
        
        # Channel 2: è¯­ä¹‰ç½®ä¿¡åº¦ä»£ä»·ï¼ˆ1 - confidenceï¼‰
        confidence_cost = 1.0 - confidence_map
        
        # å †å æˆ(batch, 3, 64, 64)
        cost_map = torch.stack([distance_cost, gradient_cost, confidence_cost], dim=1)
        
        # å±•å¹³ä¸º(batch, 12288)ä»¥ä¾¿æ‹¼æ¥åˆ°è§‚æµ‹å‘é‡
        return cost_map.view(batch, -1)
```

---

### 4. ActorCriticCNNç½‘ç»œ

**æ–‡ä»¶**: `Go2Pvcnn/rsl_rl/rsl_rl/modules/actor_critic_cnn.py`

#### ç½‘ç»œæ¶æ„
```python
class ActorCriticCNN(nn.Module):
    def __init__(self, num_obs, num_privileged_obs, num_actions, ...):
        # CNNç¼–ç å™¨ï¼ˆå¤„ç†cost_mapï¼‰
        self.cnn_encoder = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, stride=2),    # (3,64,64) -> (32,30,30)
            nn.Conv2d(32, 64, kernel_size=3, stride=2),   # (32,30,30) -> (64,14,14)
            nn.Conv2d(64, 128, kernel_size=3, stride=2),  # (64,14,14) -> (128,6,6)
            Flatten(),
            nn.Linear(128*6*6, 256)                       # (4608) -> (256)
        )
        
        # Actor: CNNç‰¹å¾(256) + Proprio(48) -> Actions
        self.actor = nn.Sequential(
            nn.Linear(256 + 48, 256),
            nn.Linear(256, num_actions)
        )
        
        # Critic: CNNç‰¹å¾(256) + Proprio(48) -> Value
        self.critic = nn.Sequential(
            nn.Linear(256 + 48, 256),
            nn.Linear(256, 1)
        )
```

#### å‰å‘ä¼ æ’­æµç¨‹
```python
def _extract_features(self, observations):
    # 1. åˆ†ç¦»è§‚æµ‹
    cost_map_flat = observations[:, -12288:]  # æœ€å12288ç»´
    proprio = observations[:, :-12288]         # å‰é¢çš„proprioè§‚æµ‹
    
    # 2. Reshape cost_map
    cost_map_2d = cost_map_flat.view(-1, 3, 64, 64)
    
    # 3. CNNç¼–ç 
    cnn_features = self.cnn_encoder(cost_map_2d)  # (batch, 256)
    
    # 4. æ‹¼æ¥ç‰¹å¾
    combined = torch.cat([cnn_features, proprio], dim=1)
    return combined
```

---

### 5. PPOç®—æ³•é›†æˆPVCNN

**æ–‡ä»¶**: `Go2Pvcnn/rsl_rl/rsl_rl/algorithms/ppo.py`

#### å‚æ•°æ‰©å±•
```python
class PPO:
    def __init__(self, ..., pvcnn_model=None, lambda_seg=0.1):
        self.pvcnn_model = pvcnn_model      # PVCNNæ¨¡å‹ï¼ˆç”¨äºå¤šä»»åŠ¡å­¦ä¹ ï¼‰
        self.lambda_seg = lambda_seg         # è¯­ä¹‰åˆ†å‰²æŸå¤±æƒé‡
```

#### ä¼˜åŒ–å™¨åŒ…å«PVCNNå‚æ•°
```python
# åœ¨train_go2_pvcnn.pyä¸­
runner.alg.pvcnn_model = pvcnn_wrapper.model
params = list(runner.alg.actor_critic.parameters()) + \
         list(pvcnn_wrapper.model.parameters())
runner.alg.optimizer = Adam(params, lr=learning_rate)
```

---

### 6. ç¯å¢ƒè§‚æµ‹é…ç½®

**æ–‡ä»¶**: `Go2Pvcnn/go2_pvcnn/tasks/go2_pvcnn_env_cfg.py`

#### Policyè§‚æµ‹ç»„ï¼ˆActorè¾“å…¥ï¼‰
```python
class PolicyCfg(ObsGroup):
    # PVCNNç‰¹å¾ (2046*4=8184ç»´ï¼Œå±•å¹³)
    pvcnn_features = ObsTerm(func=custom_mdp.pvcnn_features)
    
    # åœ°å½¢é«˜åº¦æ‰«æ (11*17=187ç»´)
    height_scan = ObsTerm(func=isaac_mdp.height_scan)
    
    # æœ¬ä½“æ„ŸçŸ¥ (48ç»´)
    base_lin_vel = ObsTerm(...)      # 3ç»´
    base_ang_vel = ObsTerm(...)      # 3ç»´
    projected_gravity = ObsTerm(...) # 3ç»´
    joint_pos = ObsTerm(...)         # 12ç»´
    joint_vel = ObsTerm(...)         # 12ç»´
    velocity_commands = ObsTerm(...) # 3ç»´
    actions = ObsTerm(...)           # 12ç»´
    
    # Cost Map (12288ç»´=3*64*64ï¼Œå±•å¹³)
    cost_map = ObsTerm(func=custom_mdp.cost_map_from_lidar)
```

#### Criticè§‚æµ‹ç»„ï¼ˆç‰¹æƒä¿¡æ¯ï¼‰
```python
class CriticCfg(ObsGroup):
    # ä¸Policyç›¸åŒçš„æ‰€æœ‰è§‚æµ‹
    # å¯ä»¥æ·»åŠ é¢å¤–çš„ç‰¹æƒä¿¡æ¯ï¼ˆå¦‚çœŸå®ç‰©ä½“ä½ç½®ç­‰ï¼‰
```

---

## ğŸ”„ å®Œæ•´è®­ç»ƒæµç¨‹

### é˜¶æ®µ1: åˆå§‹åŒ–ï¼ˆInitializationï¼‰

```
1. åŠ è½½ç¯å¢ƒé…ç½®
   â””â”€> Go2PvcnnEnvCfg
       â”œâ”€> Sceneé…ç½®ï¼ˆæœºå™¨äººã€åœ°å½¢ã€åŠ¨æ€ç‰©ä½“ï¼‰
       â”œâ”€> Observationsé…ç½®ï¼ˆpolicyç»„ + criticç»„ï¼‰
       â”œâ”€> Rewardsé…ç½®
       â””â”€> Terminationsé…ç½®

2. åˆ›å»ºPVCNN Wrapper
   â””â”€> create_pvcnn_wrapper()
       â”œâ”€> åŠ è½½é¢„è®­ç»ƒcheckpoint
       â”œâ”€> é€‚é…è¾“å…¥é€šé“ï¼ˆ9â†’3ï¼‰
       â”œâ”€> é€‚é…è¾“å‡ºç±»åˆ«ï¼ˆ13â†’4ï¼‰
       â””â”€> å†»ç»“ä¸ºevalæ¨¡å¼

3. åˆ›å»ºIsaac Labç¯å¢ƒ
   â””â”€> gym.make("Go2PvcnnEnv")
       â”œâ”€> åˆå§‹åŒ–åœºæ™¯ï¼ˆåœ°å½¢ã€æœºå™¨äººã€ç‰©ä½“ï¼‰
       â”œâ”€> åˆå§‹åŒ–ä¼ æ„Ÿå™¨ï¼ˆLiDARã€é«˜åº¦æ‰«æï¼‰
       â””â”€> åˆå§‹åŒ–è§‚æµ‹/å¥–åŠ±/ç»ˆæ­¢ç®¡ç†å™¨

4. åŒ…è£…ç¯å¢ƒ
   â””â”€> RslRlPvcnnEnvWrapper(env, pvcnn_wrapper)
       â”œâ”€> æ³¨å…¥pvcnn_wrapperåˆ°env.unwrapped
       â”œâ”€> ç¬¬ä¸€æ¬¡resetï¼ˆè®¡ç®—åˆå§‹è§‚æµ‹ï¼‰
       â””â”€> éªŒè¯è§‚æµ‹ç»´åº¦
```

### é˜¶æ®µ2: åˆ›å»ºè®­ç»ƒä»£ç†ï¼ˆCreate Agentï¼‰

```
5. é…ç½®PPOå‚æ•°
   agent_cfg = {
       "policy": {
           "class_name": "ActorCriticCNN",
           "cnn_channels": [32, 64, 128],
           "cnn_feature_dim": 256,
           ...
       },
       "algorithm": {
           "learning_rate": 1e-3,
           "lambda_seg": 0.1,
           ...
       }
   }

6. åˆ›å»ºRSL-RL Runner
   â””â”€> OnPolicyRunner(env, agent_cfg)
       â”œâ”€> åˆ›å»ºActorCriticCNNç½‘ç»œ
       â”œâ”€> åˆ›å»ºPPOç®—æ³•
       â””â”€> åˆ›å»ºRolloutStorage

7. æ³¨å…¥PVCNNåˆ°PPO
   â””â”€> runner.alg.pvcnn_model = pvcnn_wrapper.model
       â”œâ”€> é‡å»ºoptimizerï¼ˆåŒ…å«PVCNNå‚æ•°ï¼‰
       â””â”€> è®¾ç½®lambda_segæƒé‡
```

### é˜¶æ®µ3: è®­ç»ƒå¾ªç¯ï¼ˆTraining Loopï¼‰

```
å¯¹äºæ¯ä¸ªiteration:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 8. æ•°æ®æ”¶é›† (Rollout)                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    å¯¹äºæ¯ä¸ªstep (num_steps_per_env=24):
        
        a) è·å–è§‚æµ‹ (Observation)
           â””â”€> env.step() è°ƒç”¨observation_manager
               â”œâ”€> pvcnn_features():
               â”‚   â”œâ”€> ä»LiDARè·å–ç‚¹äº‘
               â”‚   â”œâ”€> è¿‡æ»¤æ— æ•ˆç‚¹
               â”‚   â”œâ”€> é‡‡æ ·åˆ°2046ç‚¹
               â”‚   â”œâ”€> é€šè¿‡PVCNNå‰å‘ä¼ æ’­
               â”‚   â””â”€> è¿”å›å±•å¹³çš„è¯­ä¹‰ç‰¹å¾ (8184ç»´)
               â”‚
               â”œâ”€> cost_map_from_lidar():
               â”‚   â”œâ”€> ä»LiDARè·å–ç‚¹äº‘
               â”‚   â”œâ”€> é€šè¿‡PVCNNè·å–è¯­ä¹‰logits
               â”‚   â”œâ”€> ç”Ÿæˆ3é€šé“cost_map (64Ã—64)
               â”‚   â””â”€> å±•å¹³ä¸ºå‘é‡ (12288ç»´)
               â”‚
               â””â”€> å…¶ä»–è§‚æµ‹ï¼ˆheight_scan, proprioç­‰ï¼‰
        
        b) é€‰æ‹©åŠ¨ä½œ (Action Selection)
           â””â”€> actor_critic.act(obs)
               â”œâ”€> _extract_features():
               â”‚   â”œâ”€> åˆ†ç¦»cost_mapå’Œproprio
               â”‚   â”œâ”€> Reshape cost_mapä¸º(3,64,64)
               â”‚   â”œâ”€> CNNç¼–ç  -> (256ç»´)
               â”‚   â””â”€> æ‹¼æ¥CNNç‰¹å¾+proprio
               â”‚
               â”œâ”€> actor(features) -> mean
               â”œâ”€> ä»N(mean, std)é‡‡æ ·åŠ¨ä½œ
               â””â”€> è¿”å›åŠ¨ä½œ + log_prob
        
        c) æ‰§è¡ŒåŠ¨ä½œ (Execute Action)
           â””â”€> env.step(action)
               â”œâ”€> ç‰©ç†ä»¿çœŸæ­¥è¿›
               â”œâ”€> è®¡ç®—å¥–åŠ±
               â”œâ”€> æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
               â””â”€> è¿”å›next_obs, reward, done
        
        d) å­˜å‚¨ç»éªŒ (Store Experience)
           â””â”€> storage.add_transitions(obs, action, reward, done, value, ...)
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 9. ç­–ç•¥æ›´æ–° (Policy Update)            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    å¯¹äºæ¯ä¸ªepoch (num_learning_epochs=5):
        
        a) è®¡ç®—ä¼˜åŠ¿å‡½æ•° (Compute Advantages)
           â””â”€> storage.compute_returns(last_value, gamma, lam)
               â””â”€> GAE: A_t = Î´_t + Î³Î»Î´_{t+1} + ...
        
        b) Mini-batchæ›´æ–° (num_mini_batches=4)
           å¯¹äºæ¯ä¸ªmini-batch:
               
               i) é‡‡æ ·batchæ•°æ®
                  â””â”€> obs, actions, values, returns, advantages, log_probs
               
               ii) å‰å‘ä¼ æ’­
                   â””â”€> actor_critic.evaluate(obs, actions)
                       â”œâ”€> actorè¾“å‡ºæ–°çš„mean
                       â”œâ”€> è®¡ç®—æ–°çš„log_prob
                       â””â”€> criticè¾“å‡ºæ–°çš„value
               
               iii) è®¡ç®—æŸå¤±
                    â”œâ”€> Surrogate Loss (PPO clip):
                    â”‚   ratio = exp(new_log_prob - old_log_prob)
                    â”‚   L_CLIP = min(ratio*A, clip(ratio)*A)
                    â”‚
                    â”œâ”€> Value Loss:
                    â”‚   L_V = (value - return)^2
                    â”‚
                    â”œâ”€> Entropy Loss:
                    â”‚   L_ENT = -mean(entropy)
                    â”‚
                    â””â”€> æ€»æŸå¤±:
                        L = -L_CLIP + value_coef*L_V - entropy_coef*L_ENT
               
               iv) åå‘ä¼ æ’­
                   â””â”€> optimizer.step()
                       â”œâ”€> æ›´æ–°ActorCriticCNNå‚æ•°
                       â””â”€> æ›´æ–°PVCNNå‚æ•°ï¼ˆå¦‚æœæœªå†»ç»“ï¼‰
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 10. æ—¥å¿—è®°å½• (Logging)                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€> TensorBoardè®°å½•
        â”œâ”€> Loss/policy_loss
        â”œâ”€> Loss/value_loss
        â”œâ”€> Policy/mean_reward
        â”œâ”€> Policy/episode_length
        â””â”€> ...
```

### é˜¶æ®µ4: ä¿å­˜ä¸è¯„ä¼°

```
11. å®šæœŸä¿å­˜æ¨¡å‹
    â””â”€> runner.save(log_dir)
        â”œâ”€> ä¿å­˜ActorCriticCNNæƒé‡
        â”œâ”€> ä¿å­˜optimizerçŠ¶æ€
        â””â”€> ä¿å­˜iterationä¿¡æ¯

12. è®­ç»ƒå®Œæˆ
    â””â”€> env.close()
        â””â”€> å…³é—­Isaac Sim
```

---

## ğŸ“Š æ•°æ®æµè¯¦è§£

### è§‚æµ‹æµï¼ˆObservation Flowï¼‰

```
LiDARä¼ æ„Ÿå™¨
    â†“ (num_rays=2046, XYZåæ ‡)
ç‚¹äº‘é¢„å¤„ç†
    â”œâ”€> è¿‡æ»¤æ— æ•ˆç‚¹ï¼ˆInf/NaN/é›¶ç‚¹ï¼‰
    â”œâ”€> FPSé‡‡æ ·æˆ–å¤åˆ¶åˆ°2046ç‚¹
    â””â”€> å½¢çŠ¶: (batch, 2046, 3)
    â†“
PVCNNå‰å‘ä¼ æ’­
    â”œâ”€> è¾“å…¥: (batch, 3, 2046)  # XYZ only
    â”œâ”€> 4å±‚PVConvç¼–ç 
    â”œâ”€> å…¨å±€ç‰¹å¾èšåˆ
    â””â”€> è¾“å‡º: {
          'logits': (batch, 4, 2046),      # 4ç±»è¯­ä¹‰
          'confidence': (batch, 2046),      # ç½®ä¿¡åº¦
          'global_features': (batch, 128)   # å…¨å±€ç‰¹å¾
        }
    â†“
åˆ†æ”¯1: PVCNN Features            åˆ†æ”¯2: Cost Map
    â†“                                â†“
å±•å¹³logits                        æŠ•å½±åˆ°2Dç½‘æ ¼
(batch, 8184)                    â”œâ”€> Distance cost
                                 â”œâ”€> Gradient cost
                                 â””â”€> Confidence cost
                                      â†“
                                 å±•å¹³(batch, 12288)
    â†“                                â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
         æ‹¼æ¥æ‰€æœ‰è§‚æµ‹
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ pvcnn_features:    8184ç»´   â”‚
    â”‚ height_scan:       187ç»´    â”‚
    â”‚ proprio:           48ç»´     â”‚
    â”‚ cost_map:          12288ç»´  â”‚
    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
    â”‚ æ€»è®¡:              20707ç»´  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
         ActorCriticCNN
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ åˆ†ç¦»cost_map (12288)        â”‚
    â”‚ åˆ†ç¦»proprio (8419)          â”‚
    â”‚         â†“                   â”‚
    â”‚ CNNç¼–ç cost_map -> 256ç»´   â”‚
    â”‚ æ‹¼æ¥CNNç‰¹å¾+proprio         â”‚
    â”‚         â†“                   â”‚
    â”‚ Actor  -> åŠ¨ä½œåˆ†å¸ƒ(12ç»´)   â”‚
    â”‚ Critic -> çŠ¶æ€ä»·å€¼(1ç»´)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ å…³é”®è®¾è®¡å†³ç­–

### 1. **ä¸ºä»€ä¹ˆå±•å¹³cost_mapï¼Ÿ**
- Isaac Labçš„ObservationManagerè¦æ±‚æ‰€æœ‰è§‚æµ‹éƒ½æ˜¯1Då‘é‡
- åœ¨ActorCriticCNNå†…éƒ¨reshapeå›2Dè¿›è¡ŒCNNå¤„ç†
- æ—¢æ»¡è¶³æ¡†æ¶è¦æ±‚ï¼Œåˆåˆ©ç”¨äº†ç©ºé—´ç»“æ„ä¿¡æ¯

### 2. **ä¸ºä»€ä¹ˆåŒæ—¶ä½¿ç”¨pvcnn_featureså’Œcost_mapï¼Ÿ**
- `pvcnn_features`: é€ç‚¹è¯­ä¹‰æ ‡ç­¾ï¼ˆé«˜ç»´ä½†å®Œæ•´ï¼‰
- `cost_map`: 2Dç©ºé—´æŠ•å½±ï¼ˆä½ç»´ä½†ç»“æ„åŒ–ï¼‰
- æä¾›äº’è¡¥ä¿¡æ¯ï¼Œæå‡ç­–ç•¥é²æ£’æ€§

### 3. **ä¸ºä»€ä¹ˆå†»ç»“PVCNNï¼Ÿ**
- PVCNNå·²åœ¨S3DISä¸Šé¢„è®­ç»ƒ
- RLæ•°æ®é‡æœ‰é™ï¼Œé¿å…è¿‡æ‹Ÿåˆ
- ä¸“æ³¨äºå­¦ä¹ è¿åŠ¨ç­–ç•¥ï¼Œè€Œéè§†è§‰ç‰¹å¾

### 4. **ä¸ºä»€ä¹ˆä½¿ç”¨FPSé‡‡æ ·ï¼Ÿ**
- ä¿æŒç‚¹äº‘å‡åŒ€åˆ†å¸ƒ
- ä¼˜äºéšæœºé‡‡æ ·ï¼ˆä¿ç•™é‡è¦å‡ ä½•ç‰¹å¾ï¼‰
- pytorch3dé«˜æ•ˆå®ç°

---

## ğŸš€ è¿è¡Œå‘½ä»¤

### è®­ç»ƒ
```bash
cd /mnt/mydisk/lhy/testPvcnnWithIsaacsim
bash Go2Pvcnn/scripts/train_go2_pvcnn.sh \
    Go2Pvcnn/scripts/train_go2_pvcnn.py \
    --num_envs 2048 \
    --max_iterations 5000 \
    --headless
```

### å¯è§†åŒ–è®­ç»ƒ
```bash
# TensorBoard
tensorboard --logdir=logs/rsl_rl/go2_pvcnn
```

### æ¢å¤è®­ç»ƒ
```bash
bash Go2Pvcnn/scripts/train_go2_pvcnn.sh \
    Go2Pvcnn/scripts/train_go2_pvcnn.py \
    --resume \
    --load_run 2025-12-15_09-03-08 \
    --num_envs 2048
```

---

## ğŸ“ å…³é”®æ–‡ä»¶è·¯å¾„

```
Go2Pvcnn/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_go2_pvcnn.py          # ä¸»è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ train_go2_pvcnn.sh          # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ go2_pvcnn/
â”‚   â”œâ”€â”€ pvcnn_wrapper.py            # PVCNNæ¨¡å‹åŒ…è£…å™¨
â”‚   â”œâ”€â”€ wrapper/
â”‚   â”‚   â””â”€â”€ pvcnn_env_wrapper.py    # RSL-RLç¯å¢ƒåŒ…è£…å™¨
â”‚   â”œâ”€â”€ mdp/
â”‚   â”‚   â”œâ”€â”€ observations.py         # è§‚æµ‹å‡½æ•°
â”‚   â”‚   â””â”€â”€ cost_map.py             # Cost mapç”Ÿæˆå™¨
â”‚   â””â”€â”€ tasks/
â”‚       â””â”€â”€ go2_pvcnn_env_cfg.py    # ç¯å¢ƒé…ç½®
â””â”€â”€ rsl_rl/
    â””â”€â”€ rsl_rl/
        â”œâ”€â”€ algorithms/ppo.py       # PPOç®—æ³•
        â””â”€â”€ modules/
            â””â”€â”€ actor_critic_cnn.py # CNNç­–ç•¥ç½‘ç»œ
```

---

## âœ… éªŒè¯æ¸…å•

- [x] PVCNNæˆåŠŸåŠ è½½å¹¶é€‚é…ï¼ˆ9â†’3é€šé“ï¼Œ13â†’4ç±»åˆ«ï¼‰
- [x] ç‚¹äº‘é¢„å¤„ç†æ­£å¸¸ï¼ˆè¿‡æ»¤+é‡‡æ ·ï¼‰
- [x] Cost mapç”Ÿæˆæ­£å¸¸ï¼ˆ3Ã—64Ã—64ï¼‰
- [x] è§‚æµ‹ç»´åº¦åŒ¹é…ï¼ˆpolicyå’Œcriticä¸€è‡´ï¼‰
- [x] ActorCriticCNNæ­£å¸¸å‰å‘ä¼ æ’­
- [x] PPOè®­ç»ƒå¾ªç¯è¿è¡Œ
- [x] TensorBoardæ—¥å¿—è®°å½•æ­£å¸¸

---

## ğŸ“ˆ é¢„æœŸè®­ç»ƒæŒ‡æ ‡

- **Episode Reward**: é€æ¸å¢åŠ ï¼ˆä»è´Ÿå€¼åˆ°æ­£å€¼ï¼‰
- **Episode Length**: ç¨³å®šåœ¨æœ€å¤§é•¿åº¦
- **Policy Loss**: æ”¶æ•›åˆ°å°å€¼
- **Value Loss**: æ”¶æ•›
- **Learning Rate**: æ ¹æ®KLæ•£åº¦è‡ªé€‚åº”è°ƒæ•´

---

## ğŸ” DebugæŠ€å·§

### æŸ¥çœ‹è§‚æµ‹ç»´åº¦
```python
# åœ¨train_go2_pvcnn.pyä¸­æ·»åŠ 
print(f"Policy obs shape: {env.observation_manager.group_obs_dim['policy']}")
print(f"Critic obs shape: {env.observation_manager.group_obs_dim['critic']}")
```

### æ£€æŸ¥PVCNNè¾“å‡º
```python
# åœ¨observations.pyä¸­æ·»åŠ 
if call_count % 100 == 1:
    print(f"PVCNN output shapes: {pvcnn_output.keys()}")
    for k, v in pvcnn_output.items():
        print(f"  {k}: {v.shape}")
```

### ç›‘æ§è®­ç»ƒç¨³å®šæ€§
```bash
# æŸ¥çœ‹lossæ˜¯å¦æœ‰NaN/Inf
grep -i "nan\|inf" logs/rsl_rl/go2_pvcnn/*/summaries.txt
```

---

**è®­ç»ƒç³»ç»Ÿå·²å®Œå…¨å°±ç»ªï¼ğŸ‰**
